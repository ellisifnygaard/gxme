---
author: "`r Sys.getenv('USERNAME')`"
date: "`r Sys.time()`"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    number_sections: true
    # self_contained: no
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 80
params:
  chr_number: 18
  # (root_dir = the chromosome subdirectory)
  # (is dependent on chr_number, so its initiated here, but updated later) 
  # root_dir: "S:/Project/SAM/Julia/Ellisif/Paper 1/DATA GWAS/Chr18_parallel_processing_partition"
  root_dir: "C:/Temp/edj079/2024-05-15_pipeline_dir/chromosomes/Chr18"

  # GWAS file
  # gwas_fileset_dir: "S:/Project/SAM/Julia/Ellisif/Paper 1/DATA GWAS/0006"
  # gwas_fileset_dir: "0101" # "hard-code" 0101
  # gwas_fileset_name: "Chr19_0006" # USE ONLY WHEN TESTING LOCALLY
  # gwas_fileset_name: "0101_gwas" # "hard-code" 0101_gwas
  
  # PLINK memory (OPTIONAL):
  # (to be used with the "--memory" flag)
  # Can be used to ensure that PLINK has enough RAM for its main workspace.
  plink_memory_mb: !r NA
  # plink_memory_mb: 42147
  
  # PLINK timeout 
  # (maximum number of seconds a call to plink.exe can take before it's stopped)
  plink_timeout: 300
  
  # Directory to export resulting files to:
  # stage_dir: "S:/Project/SAM/Julia/Ellisif/Paper 1/DATA GWAS/0101"
  stage_dir: "0201"
  
  # QC-related parameters:
  maf_minimum: 0.01
title: "`r paste0('Preliminary QC of GWAS Data - Chromosome ', params$chr_number) `"
---


```{r}
# Start timer:
start_time <- Sys.time()
```


# Make parameters into variables

The pipeline won't be Rmarkdown-based, so make variables containing the parameters stated in the YAML so that the process with building the package later won't be too arduous.

```{r}
chr_number <- params$chr_number

root_dir <- params$root_dir

gwas_fileset_dir <- "0101" # "hard-code" 0101
gwas_fileset_name <- "0101_gwas" # "hard-code" 0101_gwas
stage_dir <- params$stage_dir
maf_minimum <- params$maf_minimum

# PLINK parameters
plink_memory_mb <- params$plink_memory_mb

# TIMEOUT WHEN CALLING PLINK VIA system()
plink_timeout <- params$plink_timeout

# Specify paths for generated files:

# Report with allele frequencies generated by PLINK:
freqx_founders_path <- 
  file.path( stage_dir, paste0( stage_dir, "_founders_freq.frqx") )

# Data frame with the SNPs to exclude from GWAS fileset due to low MAF:
path_snp_low_maf <- 
  file.path( stage_dir, paste0( stage_dir, "_exclude_snps_low_maf.tsv" ) )

# Data frame with the SNPs to exclude from GWAS fileset due to non-valid
# coordinates:
path_snp_invalid <- file.path( 
  stage_dir, paste0( stage_dir, "_exclude_snps_invalid_chr_or_coord.tsv" )
)

# Data frame with the all SNPs to exclude from GWAS fileset accompanied with
# exclusion reason column:
path_snps_with_reason <- file.path(
  stage_dir, paste0( stage_dir, "_exclude_snps_all_w_reason.tsv" )
)

# Path to tsv with IDs of SNPs to be removed:
path_exclude_snps_all <- file.path(
  stage_dir, paste0( stage_dir, "_exclude_snps_all.tsv" )
)
```


# Create stage directory for output

```{r}
if( !dir.exists( stage_dir ) ){
  dir.create( stage_dir )
}

# Delete files (if any) left over from previous runs:
files_in_stage_dir <- list.files( stage_dir, full.names = TRUE )

if( length(files_in_stage_dir) > 0 ){
  message( "Deleting files that were already present in ", stage_dir, "..." )
  lapply( files_in_stage_dir, file.remove )
}
```


# Initial information and set-up

```{r include=FALSE}
# KNIT HOOK THAT ALLOWS FOR FOLDING CHUNK OUTPUT WHEN SPECIFIED
local({
  hooks <-  knitr::knit_hooks$get()
  hook_foldable <- function( type ){
    force(type)
    function( x, options ){
      res <-  hooks[[type]](x, options)

      if( base::isTRUE( options[[paste0( "fold.", type)]])){

        paste0(
          # "\n\n<details><summary>", type, "</summary>\n\n",
          "<details><summary>Click here</summary>\n\n",
          res,
          "\n\n</details>"
        )
      }
      else return(res)
    }
  }

  knitr::knit_hooks$set(
    output = hook_foldable("output"),
    plot = hook_foldable("plot")
  )
})
```

## Session info

Working directory: `r getwd()`\
R_LIBS_USER: `r Sys.getenv('R_LIBS_USER')`\
R_HOME: `r gsub(pattern = "~", replacement = " ~ ", Sys.getenv('R_HOME'))`\
HOME: `r Sys.getenv('HOME')`

```{r fold.output=TRUE}
sessionInfo()
```

## Files used by this script

-   `r  file.path( "0101", paste0( "0101_gwas_chr", params$chr_number, ".bed/bim/fam"))`
  
  
<!-- - `S:/Project/SAM/Julia/Ellisif/Paper 1/dbSNP/dbSNP deleted SNP history/SNPHistory.bcp.gz`, containing deleted SNP history from dbSNP   -->
  
<!-- - `S:/Project/SAM/Julia/Ellisif/Paper 1/dbSNP/dbSNP merge history/RsMergeArch.bcp.gz`, containing rsID merge history from dbSNP  -->
  

## Files produced by this script

-   `r  file.path( stage_dir, paste0( stage_dir, "_gwas.bed/bim/fam"))`
    
-   `r  file.path( stage_dir, paste0( stage_dir, "0201/0201_founders_freq.frqx"))`
  
-   `r  file.path( stage_dir, paste0( stage_dir, "_exclude_snps_all.tsv") )`
  
-   `r  file.path( stage_dir, paste0( stage_dir, "_exclude_snps_all_w_reason.tsv") )`
  
-   `r  file.path( stage_dir, paste0( stage_dir, "_exclude_snps_low_maf.tsv") )`
  
-   `r  file.path( stage_dir, paste0( stage_dir, "_exclude_snps_invalid_chr_or_coord.tsv"))`
  

## Rmd set up

```{r setup, include=TRUE}
knitr::opts_chunk$set(
  echo = TRUE
  # , include = FALSE # use to check report text without running any chunk code
  , warning = FALSE # hide warnings
  , message = TRUE # hide messages
  )
options(scipen = 20)
```

## Packages

```{r}
library(dplyr)
library(magrittr)
library(gt)
```


# Check PLINK set-up

**PLINK 1.90** Windows 64-bit Stable (beta 6.36, 2 Apr) Downloaded from
www.cog-genomics.org/plink2/


## Check if PLINK is in the specified root directory


```{r}
stopifnot(
  "There is no plink.exe file in the provided root_dir!" =
    file.exists("plink.exe")
)
```

# Description of QC Steps (TBD)

**The final QC steps have yet to be fully determined.**  
**Rationale:** Wait until we have a better idea of how our GWAS files were processed before Min Shi sent them to us. 
  
  
1. Remove monomorphic SNPs (`--maf 0.00001`).  
  
<!-- **OBS:** Moved to 0006!   -->
<!-- 2. Remove SNPs with IDs that do not have a matching ID in the Illumina Human610-Quad v1.0 H manifest.   -->

<!-- 3. Remove SNPs that have been annotated with `Chr`/`MapInfo` = 0 in the Illumina Human610-Quad v1.0 H manifest.   -->

<!-- 4. SNPs with rsIDs that have been permanently deleted from dbSNP *without* being merged into another rsID   -->

<!-- 5. SNPs where the PLINK filesets indicate a different chromosome than `Chr` in the Illumina manifest   -->
  


# QC Preparation

## Monomorphic + *nearly* monomorphic SNPs - Note regarding PLINK's calculation of MAF

PLINK rounds off decimal numbers to some degree. As a result, the MAF values are not particularly precise. There is no difference between using `--maf 0.00001` and `--maf 0.000000001` as the MAF computed by PLINK is only correct up to around the 4th decimal places.  
This is not a problem, however, since it's unlikely that anyone will use values that are that small.
  
  

### Create Genotype Count Report - Based on Children Only

We generate an allele frequency report using founders with `--freqx `.  

```{r}
# Genotype/allele frequency report
plink_command <- paste0( 
  "plink "
  # Choose fileset from previous stage:
  , "--bfile ", file.path( gwas_fileset_dir, gwas_fileset_name )
  # MAF counts:
  , " --freqx " # using founders only
  # EXPORT REPORT:
  , " --out "
  , gsub( "[[:punct:]]frqx$", "" ,freqx_founders_path )
  # Tell PLINK how much memory to reserve for its main workspace
  , ifelse( is.na(plink_memory_mb)
            , yes = "" # if not specified, don't add --memory flag
            , no = paste0( " --memory ", plink_memory_mb ) )
)
message( "Running PLINK using the following command:\n"
         , plink_command )

output_msg <- system( plink_command, intern = TRUE, timeout = plink_timeout )
invisible( gc() ) # garbage collection
cat(output_msg, sep = "\n")

# Import the resulting frequency report
af_founders <- read.table(
 freqx_founders_path
  , skip = 1
  , col.names = c( "chr", "snp", "a1", "a2"
                   , "count_homo_a1", "count_hetero", "count_homo_a2"
                   , "haploid_a1", "haploid_a2", "count_missing")
)

af_founders %<>% 
  mutate( maf = ( 2*count_homo_a1 + count_hetero) / # no. of minor alleles
            ( 2*( count_homo_a1 + count_hetero + count_homo_a2)) # total
  )

af_founders %>%
  head() %>%
  gt::gt() %>%
  gt::tab_options( table.font.size = "x-small" ) %>% 
  tab_header( title = md( paste0( "Glance at ", freqx_founders_path )) )
```


### SNPs where founder MAF is less than `r maf_minimum`

Export tab delimited file with the SNPs that are to be excluded based on too low MAF/being monomorphic. Will be used to create a final list of SNPs to be excluded and used with `--exclude` in PLINK later.

```{r}
snp_low_maf <- af_founders %>%
  filter( maf < maf_minimum )

dim(snp_low_maf)
head(snp_low_maf)

snp_low_maf %>% 
  select( -snp, -haploid_a1, -haploid_a2 ) %>% 
  summary()

if( nrow(snp_low_maf) > 0 ){
  snp_low_maf %>% 
    summarise( n(), n_distinct(snp), min(maf), max(maf), min(count_missing)
               , median(count_missing), max(count_missing) ) %>% 
    gt::gt() %>%
    gt::tab_options( table.font.size = "x-small" ) %>% 
    tab_header( title = paste0( "SNPs with MAF < ", maf_minimum  ) )
}
# Note that SNPs with high missing rates could have been "imputed" using
# offspring genotype and genotype of the other parent and subsequently turn out
# to have MAF above the specified limit maf_minimum

# Keep only column with SNP ID and add column with exclusion reason 
snp_low_maf %<>% 
  select(snp) %>% 
  # Add why snp is to be removed for later overview:
  mutate( exclusion_reason = "low founder maf")
# We now have a df with the SNPs to exclude later with PLINK

dim(snp_low_maf)

head(snp_low_maf) %>% 
  gt::gt() %>%
  gt::tab_options( table.font.size = "x-small" ) %>% 
  tab_header( title = paste0( "Glance at SNPs with MAF < ", maf_minimum  ) )

if( nrow(snp_low_maf) > 0 ){
  snp_low_maf %>% 
    summarise( n(), n_distinct(snp), unique(exclusion_reason) ) %>% 
    gt::gt() %>%
    gt::tab_options( table.font.size = "x-small" ) %>% 
    tab_header( 
      title = paste0( "Summary of data frame with SNPs with MAF < ", maf_minimum
      ) )
}

# Export tab delimited file:
snp_low_maf %>% readr::write_tsv( .
                                  , file = path_snp_low_maf
                                  , col_names = FALSE )
# No longer needed:
rm( af_founders, snp_low_maf )
```


## SNPs where `chr` and/or `coord` in the bim file is zero or any other invalid value 

We want to remove SNPs whose `chr` or `coord` is **not** an integer greater than zero.  

```{r}
bim <- readr::read_delim(
  file.path( gwas_fileset_dir, paste0( gwas_fileset_name, ".bim" ) )
  , col_names = c( "chr", "snp", "pos", "coord", "allele_1", "allele_2" )
  , show_col_types = FALSE
)

# Chromosome:
snp_invalid_chr <- bim %>% 
  filter( !( as.numeric( chr ) %% 1 == 0 & chr > 0) ) %>%
  select( snp ) %>% 
  # Add why snp is to be removed for later overview:
  mutate( exclusion_reason = "chr in bim file was not a whole number > 0")

# Coordinate:
snp_invalid_coord <- bim %>% 
  filter( !( as.numeric( coord ) %% 1 == 0 & coord > 0 )
  ) %>%
  select( snp ) %>% 
  # Add why snp is to be removed for later overview:
  mutate( exclusion_reason = "coord in bim file was not a whole number > 0")

# Combine dfs:
snp_invalid_chr_or_coord <- dplyr::bind_rows( snp_invalid_chr
                                               , snp_invalid_coord )

dim(snp_invalid_chr_or_coord)

head(snp_invalid_chr_or_coord) %>% 
  gt::gt() %>%
  gt::tab_options( table.font.size = "x-small" ) %>% 
  tab_header( title = "Glance SNPs with non-valid coordinates" )

snp_invalid_chr_or_coord %>% 
  summarise( n(), n_distinct(snp) ) %>% 
  gt::gt() %>%
  gt::tab_options( table.font.size = "x-small" ) %>% 
  tab_header( title = "Summary of SNPs with non-valid coordinates" )


# Export tab delimited file:
snp_invalid_chr_or_coord %>% 
  readr::write_tsv( ., file = path_snp_invalid, col_names = FALSE )

# No longer needed:
rm( bim, snp_invalid_chr, snp_invalid_coord, snp_invalid_chr_or_coord )
```



## Combine all the lists of SNPs to exclude into one list and write to tsv

The `--exclude` flag in PLINK appears to only accept *one* file with SNPs to exclude. Hence, we'll now combine all the separate lists that we made earlier with SNPs that we want to exclude, into one large list, and subsequently export it as a tsv file.  

### Read all the separate lists from their tsv file and combine them into one df

```{r}
# Bind rows of all the SNP lists together (duplicate SNPs can occur)
exclude_snps_all <- dplyr::bind_rows(
  readr::read_tsv( path_snp_low_maf
                   , col_names = c( "snp", "exclusion_reason")
                   , show_col_types = FALSE
  )
  , readr::read_tsv( path_snp_invalid
                   , col_names = c( "snp", "exclusion_reason")
                   , show_col_types = FALSE
  )

)
dim( exclude_snps_all )

# See if there are duplicates:
exclude_snps_all %>%
  summarise( n(), n_distinct(snp), n_distinct( exclusion_reason ) ) %>% 
  gt::gt() %>%
  gt::fmt_integer() %>% 
  gt::tab_options(table.font.size = "x-small") %>% 
  tab_header( title = "Summary of SNPs flagged for removal" )

# Ensure that all the SNP IDs are in upper case and check again
exclude_snps_all %<>% mutate( snp = toupper(snp) )
exclude_snps_all %>% summarise( n(), n_distinct(snp) )

# Arrange by SNP ID and reason
exclude_snps_all %<>% arrange( snp, exclusion_reason )

# Export to tsv s.t. we have a list of all the SNPs to exclude and reason for
# exclusion (df in long format)
exclude_snps_all %>% 
  readr::write_tsv( .
                    , file = path_snps_with_reason
                    , col_names = TRUE
  )
```


### Overview of excluded SNPs per exclusion criteria

```{r}
# Make df wider so that we can get an overview of SNPs falling into multiple
# exclusion criteria (unless there are zero rows in the df)
if( nrow( exclude_snps_all ) > 1 ){
  exclude_snps_all %>% 
    mutate( n = TRUE ) %>% 
    tidyr::pivot_wider( names_from = exclusion_reason
                        , values_from = n
                        , values_fill = FALSE ) %>% 
    # Group by all columns except snp, and then count (so that the code can
    # handle cases where one or several tsv files are empty)
    group_by( across( c(-snp) ) ) %>% 
    count() %>% 
    janitor::adorn_totals( "row" ) %>% 
    gt::gt() %>%
    gt::fmt_integer() %>% 
    gt::tab_options(table.font.size = "x-small")
}
```


### Make list of unique SNPs to exclude and export to tsv file (for PLINK)

```{r}
# Make df with one row per unique SNP:
exclude_snps_all %<>% 
  select( snp ) %>% 
  distinct() %>% 
  arrange( snp ) %>% 
  # Make sure all the letter prefixes are in upper case to match PLINK filesets:
  mutate( snp = toupper(snp) )

dim( exclude_snps_all )
head( exclude_snps_all )

# Export the SNPs to a tsv file;
exclude_snps_all %>% 
  readr::write_tsv( .
                    , file = path_exclude_snps_all
                    , col_names = FALSE
  )

# Import the tsv file to check that everything went OK:
exclude_snps_all_exported <- readr::read_tsv(
  path_exclude_snps_all
  , col_names = c("snp")
  , show_col_types = FALSE
)
invisible( gc() ) # garbage collection

# Stop unless all the SNPs in exclude_snps_all were successfully exported:
if( !all( exclude_snps_all$snp %in% exclude_snps_all_exported$snp ) ){
  stop( "Not all SNPs were successfully exported to "
        , path_exclude_snps_all
        , "! Please try again." )
}
rm( exclude_snps_all_exported )
```



# Perform QC and Export to Binary Fileset


```{r}
plink_command <- paste0( 
  "plink "
  # Choose fileset from 0101:
  , "--bfile ", file.path( gwas_fileset_dir, gwas_fileset_name )
  
  # Remove the SNPs in our exclusion list:
  ,  " --exclude " 
  , path_exclude_snps_all
  # (i.e. get rid of SNPs that fit our exclusion criteria)
  
  # Export output to a binary fileset
  ,  " --make-bed " 
  , "--out "
  , file.path( stage_dir, paste0( stage_dir, "_gwas" ) )
  # Tell PLINK how much memory to reserve for its main workspace
  , ifelse( is.na(plink_memory_mb)
            , yes = "" # if not specified, don't add --memory flag
            , no = paste0( " --memory ", plink_memory_mb ) )
)
message( "Running PLINK using the following command:\n"
         , plink_command )

output_msg <- system( plink_command, intern = TRUE, timeout = plink_timeout )
invisible( gc() ) # garbage collection
cat(output_msg, sep = "\n")

# Stop if the new gwas files do not exist:
stopifnot( file.exists( file.path( 
  stage_dir, paste0( stage_dir, "_gwas.", c("bed", "bim", "fam") )
) ) )
```


# Check the QC'ed Data

**Evaluate whether these chunks should be completely removed at some point or incorporated as formal tests for errors somehow in the pipeline.**

## Check that QC'ed data exists in `r stage_dir``

```{r}
stopifnot( file.exists( file.path( stage_dir, "0201_gwas.log" ) ) )
stopifnot( file.exists( file.path( stage_dir, "0201_gwas.bim" ) ) )
stopifnot( file.exists( file.path( stage_dir, "0201_gwas.fam" ) ) )
stopifnot( file.exists( file.path( stage_dir, "0201_gwas.bed" ) ) )
```



## bim files

```{r}
# Import bim from QC'ed fileset:
bim_0201 <- readr::read_delim(
  file.path(stage_dir, paste0( stage_dir, "_gwas", ".bim" ) )
  , col_names = c( "chr", "snp", "pos", "coord", "allele_1", "allele_2" )
  , show_col_types = FALSE
)

# Import bim from original fileset:
bim_0101 <- readr::read_delim(
  # file.path( stage_dir, paste0( stage_dir, "_gwas.bim" ) )
  file.path( "0101", paste0( "0101", "_gwas.bim" ) )
  , col_names = c( "chr", "snp", "pos", "coord", "allele_1", "allele_2" )
  , show_col_types = FALSE
)
invisible( gc() ) # garbage collection


# Number of SNPs that were removed during QC:
sum( !(bim_0101$snp %in% bim_0201$snp) )
sum( !(bim_0101$snp %in% bim_0201$snp) ) == nrow( exclude_snps_all )

# Stop unless all the SNPs in exclude_snps_all were removed from the PLINK
# filesets:
if( any( exclude_snps_all$snp %in% bim_0201$snp ) ){
  stop( "Removing all the SNPs in "
        , path_exclude_snps_all
        , " from the PLINK filesets appears to have been unsuccessful.")
}

# Get vector with all the SNPs removed during QC and compare w exclude_snps_all:
snps_removed_during_qc <- bim_0101 %>% 
  filter( !(snp %in% bim_0201$snp) ) %>% 
  pull( snp )

all( snps_removed_during_qc %in% exclude_snps_all$snp )
all( exclude_snps_all$snp %in% snps_removed_during_qc )

# Update user on how many SNPs there were before QC and after QC:
message( "There were ", nrow(bim_0101), " SNPs prior to QC.\n"
         , length( snps_removed_during_qc ), " were removed, leaving "
         , nrow( bim_0201 ), " SNPs in the GWAS data."
         )
```


```{r}
# Stop timer:
end_time <- Sys.time()

script_execution_time <- end_time -start_time

cat("The execution time of this script was", as.numeric( script_execution_time, units = "secs" ), "seconds.")
```


# The execution time of this script was __`r round( as.numeric( script_execution_time, units = "mins" ), 3)` minutes__.

# Log execution time

Export data frame with execution time for later collation with execution times of the other stages so that one can create tables with the execution time chromosome and/or stage.

```{r}
# Create folder for csv file if it does not already exist
pipeline_dir <- dirname( dirname( root_dir ) )
stage_execution_time_dir <- 
  file.path( pipeline_dir, "Results", "Preprocessing_stage_execution_times" )

if( !dir.exists( stage_execution_time_dir ) ){
  dir.create( stage_execution_time_dir )
}

exec_time_df <- data.frame(
  stage = stage_dir
  , chr = chr_number
  , script_execution_time_seconds = 
    as.numeric( script_execution_time, units = "secs" )
  , script_start_time = start_time
  , computername = Sys.getenv("COMPUTERNAME")
  , pipeline_dir = pipeline_dir
  , cpu_model = benchmarkme::get_cpu()$model_name
  , no_of_cores = benchmarkme::get_cpu()$no_of_cores
  , ram_iec_units = print(benchmarkme::get_ram(), unit_system = "iec")
  , system_memory_total_Mb = ps::ps_system_memory()$total / 1024^2
  , system_memory_avail_Mb = ps::ps_system_memory()$avail / 1024^2
  , R_platform = R.version$platform
  , R_version = R.version$version.string
  , Platform_GUI = .Platform$GUI
  , RStudio_version = ifelse( .Platform$GUI == "RStudio"
                              , yes = as.character(rstudioapi::getVersion())
                              , no = NA )
)

# Display data frame with log data frame
exec_time_df %>% 
  gt::gt() %>% 
  tab_options( table.font.size = "x-small" ) %>% 
  tab_header( title = md( paste0( "Stage execution time log - Stage "
                                      , stage_dir
                                      , " - Chromosome "
                                      , chr_number )
  ) )

# Export data frame to stage_execution_time_dir
exec_time_df %>% readr::write_csv2( 
  . 
  , file = file.path( stage_execution_time_dir
                 , paste0( stage_dir, "_", sprintf("chr%02d.csv", chr_number )))
  , append = FALSE # overwrite existing files
)
```

# Complete session info

```{r fold.output=TRUE}
sessionInfo()
```
